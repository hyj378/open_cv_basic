<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
  <title>cv::xfeatures2d::SIFT</title>
</head>
<style>
  h1
  {
    border: 1.5px solid green;
    margin: 0.8%;
    padding: 0.8%;
    width: 23%;
  }
  #Parameters
  {
    width: 80%;
    padding: 50px;
  }
  #fx
  {
    margin: 10px;
    width: 45%;
    border: 1.5px solid green;
  }
  img
  {
    width: 60%;
    height: 78%;
    margin: 0.3%;
  }
</style>
<body>
  <header>
    <p><a href="..\index.html">메인페이지로</a>&nbsp
    <a href="..\namespace_cv.html">namespace cv 페이지로</a></p>
    <p><a href="xfeatures2d.html">namespace cv::xfeatures2d 페이지로</a></p>
    <h1>cv::xfeatures2d::SIFT</h1>
  </header>
  <nav>

  </nav>

  <article>
<p>Class SIFT : SIFF알고리즘을 사용하여 키포인트 및 컴퓨팅 설명자를 추출하는 클래스</p>
<p>typedef SIFT SiftDescriptorExtractor<br>
typedef SIFT SiftFeatureDetector<br>
정의된 헤더 : #include “nonfree.hpp”</p>
<p>상속된 다이어그램:
cv::Algorithm >> cv::Feature2D >> cv::xfeatures2d::SIFT
</p>

맴버 함수 설명:
<div id=fx><h3><pre>
  SIFT 포인터를 반환하는 create함수

  static Ptr<SIFT> cv::xfeatures2d::SIFT::create	(
  		int 	nfeatures = 0,
  		int 	nOctaveLayers = 3,
  		double 	contrastThreshold = 0.04,
  		double 	edgeThreshold = 10,
  		double 	sigma = 1.6
  	)
</pre></h3></div>
<div id=Parameters>
변수의 의미:<br>
<h3>nfeatures</h3>	The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast)
남길 특징점의 개수(SIFT의 지역대비로 측정)
<h3>nOctaveLayers</h3>
The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.옥타브 층의 수이다 기본값 3은 D. Lowe의 논문에서 발표한 값이다.
<h3>contrastThreshold</h3>
The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.
임계값 (책의 191페이지를 보면 SIFT알고리즘은 특징점을 찾을 때 DOG를 이용하는데 DOG영상에서 특징점을 취할 때 이웃 점 중 최대 또는 최소가 되는 점을 취한다. 이러한 비교가 어려울 때(균일하지 않은, 대비가 적은 영역) 임계값을 이용해 특징점을 검출하는 것 같다.
<h3>edgeThreshold</h3>	The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are filtered out (more features are retained).
모서리 모양의 특징을 걸러내는데 사용되는 임계값이다. 이 값이 클수록 더 적은 특징이 걸러진다. 즉 더 많은 특징을 반환한다.
<h3>sigma</h3>	The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.
0층의 옥타브의 이미지(토대 영상)에 적용되는 분산값로 영상의 품질에 따라 조절 가능하다. 기본값은 1.6으로 실험을 통한 결과이다.</div>
<br><br>
알고리즘 설명:<br><br>
<img src="..\img\SIFT(1).jpg"><br>
위는 스케일 공간을 구축하는 방법에 대한 사진이다<br>
&nbsp&nbsp이렇게 구축한 공간에서 정규 라플라시안과 유사한 DOG(different of gaussian)식을 통해&nbsp
한 옥타브에서 5개의 DOG영상을 얻는다.(DOG는 이웃한 두 영상의 같은 위치의 화소간의 차)<br>
&nbsp&nbsp이 5개의 영상 중 맨 앞과 맨끝을 제외한 3개의 영상에서 이웃한 화소 중 최대 또는 최소값을&nbsp
특징점으로 취하되, 임계값보다 작은 극점은 제외한다.<br>
&nbsp&nbsp이렇게 검출된 극점은 <y, x:옥타브o에서의 좌표, o:옥타브 번호, i:DOG번호>정보를 갖고&nbsp
이를 변환하여 <y, x:0옥타브에서의 좌표, s스케일 값>을 얻을 수 있다.<br>
<h1><a href="https://docs.opencv.org/3.4.3/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html">더 많은 정보</a></h1>
  </article>
</body>
</html>
